{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '../data/processed'\n",
    "DATASET_TRAIN = DATASET_ROOT + '/train'\n",
    "DATASET_TEST = DATASET_ROOT + '/test'\n",
    "\n",
    "SAVED_MODELS_PATH = '../saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1615 images belonging to 3 classes.\n",
      "Found 283 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_TRAIN,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        DATASET_TEST,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def vgg16_based_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(150, 150, 3)))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x, name='vgg16_based')\n",
    "    return model\n",
    "\n",
    "\n",
    "def residual_block(x, filters_num):\n",
    "    x_residual = x\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters_num, (3, 3), padding='same')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters_num, (3, 3), padding='same')(x)\n",
    "    \n",
    "    x = tf.keras.layers.add([x, x_residual])\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample(x, filters_num):\n",
    "    x = Conv2D(filters_num, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_simple_model():\n",
    "    model_input = Input(shape=(150, 150, 3))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = downsample(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = downsample(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = downsample(x, 64)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=x, name='simple_residual')\n",
    "    return model\n",
    "              \n",
    "    \n",
    "model = resnet_simple_model()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_residual\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 150, 150, 3)  12          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 150, 150, 64) 1792        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 150, 150, 64) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 150, 150, 64) 256         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 150, 150, 64) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 150, 150, 64) 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 150, 150, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 150, 150, 64) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 150, 150, 64) 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 150, 150, 64) 0           conv2d_19[0][0]                  \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 150, 150, 64) 256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 150, 150, 64) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 150, 150, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 150, 150, 64) 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 150, 150, 64) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 150, 150, 64) 36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 150, 150, 64) 0           conv2d_21[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 75, 75, 128)  131200      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 75, 75, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 75, 75, 128)  512         batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 75, 75, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 75, 75, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 75, 75, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 75, 75, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 75, 75, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 75, 75, 128)  0           conv2d_24[0][0]                  \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 75, 75, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 75, 75, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 75, 75, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 75, 75, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 75, 75, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 75, 75, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 75, 75, 128)  0           conv2d_26[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 38, 38, 128)  262272      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 38, 38, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 38, 38, 128)  512         batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 38, 38, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 38, 38, 128)  147584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 38, 38, 128)  512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 38, 38, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 38, 38, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 38, 38, 128)  0           conv2d_29[0][0]                  \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 38, 38, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 38, 38, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 38, 38, 128)  147584      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 38, 38, 128)  512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 38, 38, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 38, 38, 128)  147584      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 38, 38, 128)  0           conv2d_31[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 19, 19, 64)   131136      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 19, 19, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 23104)        0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           1478720     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3)            195         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,340,111\n",
      "Trainable params: 3,336,905\n",
      "Non-trainable params: 3,206\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time_now = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "path_to_save = SAVED_MODELS_PATH + '/' + model.name + '_' + time_now\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(path_to_save, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 17 steps\n",
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.5591INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 1.5297 - accuracy: 0.5610 - val_loss: 9.5134 - val_accuracy: 0.1176\n",
      "Epoch 2/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.0940 - accuracy: 0.5597INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.0918 - accuracy: 0.5597 - val_loss: 1.0592 - val_accuracy: 0.5478\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 1.0804 - accuracy: 0.5522 - val_loss: 16.5909 - val_accuracy: 0.5515\n",
      "Epoch 4/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.9925 - accuracy: 0.5805INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.9913 - accuracy: 0.5816 - val_loss: 0.9086 - val_accuracy: 0.5625\n",
      "Epoch 5/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.5445INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.9533 - accuracy: 0.5435 - val_loss: 0.8354 - val_accuracy: 0.6287\n",
      "Epoch 6/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.9072 - accuracy: 0.5698INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.9063 - accuracy: 0.5716 - val_loss: 0.8204 - val_accuracy: 0.6360\n",
      "Epoch 7/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.9013 - accuracy: 0.5907INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.9036 - accuracy: 0.5891 - val_loss: 0.7764 - val_accuracy: 0.6654\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.8741 - accuracy: 0.6141 - val_loss: 0.9057 - val_accuracy: 0.6654\n",
      "Epoch 9/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8641 - accuracy: 0.6035INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.8640 - accuracy: 0.6019 - val_loss: 0.7155 - val_accuracy: 0.7353\n",
      "Epoch 10/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8336 - accuracy: 0.6241INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__15_14_00/assets\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.8310 - accuracy: 0.6254 - val_loss: 0.7080 - val_accuracy: 0.7096\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 96s 964ms/step - loss: 0.8367 - accuracy: 0.6148 - val_loss: 0.7470 - val_accuracy: 0.6691\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.8337 - accuracy: 0.6248 - val_loss: 0.7417 - val_accuracy: 0.7279\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.8206 - accuracy: 0.6266 - val_loss: 0.7730 - val_accuracy: 0.6838\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 0.8232 - accuracy: 0.6216 - val_loss: 0.7173 - val_accuracy: 0.7096\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.8432 - accuracy: 0.6291 - val_loss: 0.7844 - val_accuracy: 0.7022\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.8398 - accuracy: 0.6129 - val_loss: 0.7980 - val_accuracy: 0.6360\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 98s 981ms/step - loss: 0.8107 - accuracy: 0.6435 - val_loss: 0.7337 - val_accuracy: 0.7169\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.8070 - accuracy: 0.6354 - val_loss: 0.8230 - val_accuracy: 0.7206\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 97s 967ms/step - loss: 0.8088 - accuracy: 0.6598 - val_loss: 0.7382 - val_accuracy: 0.7279\n",
      "Epoch 20/30\n",
      " 12/100 [==>...........................] - ETA: 1:20 - loss: 0.8218 - accuracy: 0.6354"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEP_SIZE_VALID,\n",
    "        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid19': 0, 'normal': 1, 'pneumonia': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.80564892e-01, 1.00966240e-03, 1.84253529e-02],\n",
       "       [9.98408616e-01, 1.35691429e-03, 2.34432868e-04],\n",
       "       [1.85787141e-01, 2.45802314e-03, 8.11754823e-01],\n",
       "       [8.82703602e-01, 4.96908017e-02, 6.76055923e-02],\n",
       "       [9.65985537e-01, 7.67677338e-05, 3.39375809e-02],\n",
       "       [7.69713987e-03, 3.77599835e-01, 6.14703059e-01],\n",
       "       [5.21438897e-01, 1.46525025e-01, 3.32036078e-01],\n",
       "       [5.12951054e-04, 2.81295609e-02, 9.71357465e-01],\n",
       "       [2.68457979e-02, 2.20829621e-02, 9.51071203e-01],\n",
       "       [6.45843923e-01, 2.64105462e-02, 3.27745497e-01],\n",
       "       [9.85803604e-01, 4.63191974e-08, 1.41964024e-02],\n",
       "       [6.81705356e-01, 8.76591261e-03, 3.09528738e-01],\n",
       "       [3.47172879e-02, 8.78305137e-01, 8.69775489e-02],\n",
       "       [9.37520921e-01, 3.82816494e-02, 2.41974518e-02],\n",
       "       [1.63490721e-03, 1.22156314e-04, 9.98242974e-01],\n",
       "       [9.73263502e-01, 8.67961254e-03, 1.80568136e-02],\n",
       "       [8.41397643e-01, 8.11524596e-03, 1.50487110e-01],\n",
       "       [3.90892774e-01, 2.70445220e-04, 6.08836770e-01],\n",
       "       [9.87627506e-01, 1.64100341e-03, 1.07314624e-02],\n",
       "       [9.66900468e-01, 1.98623475e-05, 3.30796726e-02],\n",
       "       [9.43400085e-01, 5.39788569e-04, 5.60600795e-02],\n",
       "       [1.83911309e-01, 7.49992486e-03, 8.08588743e-01],\n",
       "       [8.53243470e-01, 2.23554351e-04, 1.46532938e-01],\n",
       "       [6.68888073e-03, 1.47278130e-01, 8.46032977e-01],\n",
       "       [8.55047822e-01, 1.23392954e-01, 2.15592384e-02],\n",
       "       [3.85432929e-01, 2.17773452e-01, 3.96793634e-01],\n",
       "       [8.82590234e-01, 1.27088481e-06, 1.17408477e-01],\n",
       "       [7.65351281e-02, 4.37208377e-02, 8.79744112e-01],\n",
       "       [8.25597465e-01, 3.64581905e-02, 1.37944341e-01],\n",
       "       [7.12990940e-01, 2.84626096e-01, 2.38292059e-03],\n",
       "       [9.98804212e-01, 3.01397195e-05, 1.16565567e-03],\n",
       "       [9.98153746e-01, 1.13396859e-03, 7.12310197e-04],\n",
       "       [8.44006172e-06, 9.45237339e-01, 5.47541827e-02],\n",
       "       [4.60032940e-01, 5.01773119e-01, 3.81939374e-02],\n",
       "       [2.66914594e-05, 9.98912573e-01, 1.06071203e-03],\n",
       "       [1.67270785e-03, 9.94494855e-01, 3.83243547e-03],\n",
       "       [3.94508243e-03, 9.75455940e-01, 2.05990598e-02],\n",
       "       [1.90166902e-04, 9.71307278e-01, 2.85026375e-02],\n",
       "       [7.70886079e-04, 9.07272279e-01, 9.19568017e-02],\n",
       "       [1.27094754e-04, 9.71744776e-01, 2.81281751e-02],\n",
       "       [8.61961041e-07, 9.99749482e-01, 2.49705161e-04],\n",
       "       [7.88429588e-06, 9.99809682e-01, 1.82448130e-04],\n",
       "       [7.53465656e-06, 9.99634147e-01, 3.58341349e-04],\n",
       "       [2.21791473e-04, 9.75180745e-01, 2.45974138e-02],\n",
       "       [5.20633650e-04, 9.81554031e-01, 1.79253668e-02],\n",
       "       [2.99191061e-06, 9.99319673e-01, 6.77377102e-04],\n",
       "       [2.29697744e-05, 9.96736467e-01, 3.24058789e-03],\n",
       "       [6.81717502e-05, 9.98727500e-01, 1.20423047e-03],\n",
       "       [2.80634680e-07, 9.99781668e-01, 2.18115529e-04],\n",
       "       [3.47245820e-02, 9.47267652e-01, 1.80078167e-02],\n",
       "       [6.10788492e-03, 9.65209544e-01, 2.86826249e-02],\n",
       "       [2.01383093e-03, 9.91120517e-01, 6.86562108e-03],\n",
       "       [6.30218675e-03, 1.29664660e-01, 8.64033103e-01],\n",
       "       [8.10444262e-03, 2.76597798e-01, 7.15297759e-01],\n",
       "       [7.52930413e-04, 9.98084188e-01, 1.16286369e-03],\n",
       "       [5.26755303e-03, 3.15938413e-01, 6.78794026e-01],\n",
       "       [3.28383176e-04, 9.01302993e-01, 9.83686447e-02],\n",
       "       [4.63796823e-05, 9.98118401e-01, 1.83523051e-03],\n",
       "       [3.41557870e-06, 9.98229086e-01, 1.76742568e-03],\n",
       "       [2.40570195e-02, 6.92030609e-01, 2.83912390e-01],\n",
       "       [3.15671414e-02, 4.96963173e-01, 4.71469730e-01],\n",
       "       [6.53992295e-02, 9.20243144e-01, 1.43576143e-02],\n",
       "       [4.35412148e-05, 9.66929555e-01, 3.30269076e-02],\n",
       "       [7.08252424e-03, 9.18950260e-01, 7.39671364e-02],\n",
       "       [1.08128319e-04, 9.90046561e-01, 9.84537881e-03],\n",
       "       [3.04507732e-04, 3.36938173e-01, 6.62757277e-01],\n",
       "       [4.31634544e-04, 8.37385237e-01, 1.62183121e-01],\n",
       "       [7.51707557e-06, 9.90411162e-01, 9.58129298e-03],\n",
       "       [2.12673040e-04, 9.98784482e-01, 1.00286608e-03],\n",
       "       [3.28215468e-03, 9.93687928e-01, 3.02990479e-03],\n",
       "       [1.51158329e-05, 9.98159111e-01, 1.82573881e-03],\n",
       "       [3.87258842e-06, 9.82696056e-01, 1.73000284e-02],\n",
       "       [1.11050892e-03, 9.72685933e-01, 2.62035951e-02],\n",
       "       [4.89861577e-06, 9.99583304e-01, 4.11808956e-04],\n",
       "       [1.09983864e-06, 6.35744989e-01, 3.64253908e-01],\n",
       "       [3.63815598e-05, 9.90529835e-01, 9.43374448e-03],\n",
       "       [2.25332697e-04, 9.98947203e-01, 8.27497395e-04],\n",
       "       [6.61571686e-09, 9.99665141e-01, 3.34828743e-04],\n",
       "       [8.80063713e-01, 1.35844154e-02, 1.06351867e-01],\n",
       "       [1.30680093e-07, 9.99887466e-01, 1.12373185e-04],\n",
       "       [1.30005705e-04, 9.69869375e-01, 3.00005935e-02],\n",
       "       [5.42368852e-02, 6.98737144e-01, 2.47025877e-01],\n",
       "       [2.26176644e-06, 9.99397874e-01, 5.99861145e-04],\n",
       "       [2.72367032e-07, 9.99988794e-01, 1.09541861e-05],\n",
       "       [3.65884596e-04, 9.90725577e-01, 8.90854001e-03],\n",
       "       [1.20264536e-04, 9.97896671e-01, 1.98298320e-03],\n",
       "       [1.53414639e-05, 8.46358001e-01, 1.53626695e-01],\n",
       "       [3.66315871e-05, 9.98124778e-01, 1.83855684e-03],\n",
       "       [8.99717852e-05, 9.94277179e-01, 5.63289877e-03],\n",
       "       [9.93685717e-06, 9.99926209e-01, 6.39343853e-05],\n",
       "       [1.41442195e-03, 9.81126845e-01, 1.74587965e-02],\n",
       "       [5.09155252e-05, 9.22069371e-01, 7.78797939e-02],\n",
       "       [1.43402394e-05, 9.92837012e-01, 7.14861322e-03],\n",
       "       [1.75899413e-06, 9.84574616e-01, 1.54236341e-02],\n",
       "       [8.95336620e-04, 7.98801854e-02, 9.19224441e-01],\n",
       "       [4.87998081e-03, 9.77414370e-01, 1.77057255e-02],\n",
       "       [9.79803372e-06, 9.98616457e-01, 1.37378590e-03],\n",
       "       [2.49634795e-05, 9.97169912e-01, 2.80511659e-03],\n",
       "       [8.32936552e-04, 9.94010091e-01, 5.15701808e-03],\n",
       "       [2.08709280e-05, 9.92071807e-01, 7.90733192e-03],\n",
       "       [1.67713253e-04, 9.98895884e-01, 9.36400611e-04],\n",
       "       [2.93655339e-05, 9.56651390e-01, 4.33192663e-02],\n",
       "       [6.30854105e-04, 1.90601125e-02, 9.80309010e-01],\n",
       "       [4.65831906e-03, 3.10483910e-02, 9.64293301e-01],\n",
       "       [2.11015344e-04, 9.78445649e-01, 2.13433634e-02],\n",
       "       [7.14403432e-05, 9.93159115e-01, 6.76953653e-03],\n",
       "       [1.22940969e-02, 9.55301881e-01, 3.24039869e-02],\n",
       "       [7.13017362e-04, 9.91859615e-01, 7.42743816e-03],\n",
       "       [3.52852829e-02, 8.80742967e-01, 8.39717388e-02],\n",
       "       [1.06515596e-03, 9.95496511e-01, 3.43827391e-03],\n",
       "       [3.32566979e-03, 9.47076321e-01, 4.95980158e-02],\n",
       "       [2.88407039e-03, 9.86733139e-01, 1.03828125e-02],\n",
       "       [5.57292893e-04, 9.49577451e-01, 4.98652384e-02],\n",
       "       [4.73873079e-05, 9.75994229e-01, 2.39584465e-02],\n",
       "       [4.45983824e-06, 9.99864936e-01, 1.30581306e-04],\n",
       "       [6.28025038e-04, 4.57429379e-01, 5.41942596e-01],\n",
       "       [3.07604368e-03, 6.40369296e-01, 3.56554657e-01],\n",
       "       [5.08274843e-06, 9.96063054e-01, 3.93178500e-03],\n",
       "       [7.32003027e-05, 9.83014345e-01, 1.69123653e-02],\n",
       "       [1.72380749e-02, 5.46945512e-01, 4.35816437e-01],\n",
       "       [2.26066746e-02, 2.32958943e-01, 7.44434357e-01],\n",
       "       [3.20832623e-05, 9.91120398e-01, 8.84743407e-03],\n",
       "       [9.53980134e-07, 9.99977350e-01, 2.16417466e-05],\n",
       "       [1.45655065e-07, 9.88992512e-01, 1.10073239e-02],\n",
       "       [7.18522460e-06, 9.98765945e-01, 1.22691528e-03],\n",
       "       [1.24975835e-04, 5.84214747e-01, 4.15660322e-01],\n",
       "       [1.38140867e-05, 9.99765933e-01, 2.20221453e-04],\n",
       "       [4.23740312e-05, 9.99926209e-01, 3.15226971e-05],\n",
       "       [1.17496261e-03, 9.91763115e-01, 7.06200954e-03],\n",
       "       [2.07425654e-02, 9.57432508e-01, 2.18249485e-02],\n",
       "       [1.44724536e-03, 7.07372546e-01, 2.91180134e-01],\n",
       "       [1.32055493e-06, 9.99483109e-01, 5.15533204e-04],\n",
       "       [7.11040229e-07, 9.99900103e-01, 9.91728957e-05],\n",
       "       [2.29125115e-04, 9.90088761e-01, 9.68212727e-03],\n",
       "       [1.11651269e-03, 9.63139594e-01, 3.57439369e-02],\n",
       "       [5.00825308e-06, 9.97472584e-01, 2.52240617e-03],\n",
       "       [3.18376224e-05, 9.48857486e-01, 5.11107519e-02],\n",
       "       [5.12739934e-04, 9.99443114e-01, 4.41353732e-05],\n",
       "       [3.83437000e-04, 9.92353022e-01, 7.26358546e-03],\n",
       "       [2.17010844e-02, 8.85833561e-01, 9.24653262e-02],\n",
       "       [1.35201888e-04, 9.97896075e-01, 1.96863711e-03],\n",
       "       [5.10256177e-06, 9.99424458e-01, 5.70475357e-04],\n",
       "       [8.66728127e-02, 7.30933920e-02, 8.40233803e-01],\n",
       "       [1.94512904e-04, 8.51659298e-01, 1.48146227e-01],\n",
       "       [3.52161378e-02, 7.72939026e-01, 1.91844910e-01],\n",
       "       [6.65101061e-06, 9.99904871e-01, 8.84862529e-05],\n",
       "       [5.38339646e-06, 9.99964356e-01, 3.03219349e-05],\n",
       "       [1.76941173e-03, 9.43149686e-01, 5.50809018e-02],\n",
       "       [1.83890893e-06, 9.97797370e-01, 2.20088172e-03],\n",
       "       [4.37801054e-06, 9.96780515e-01, 3.21510690e-03],\n",
       "       [9.85932274e-06, 9.99314427e-01, 6.75642281e-04],\n",
       "       [9.40763948e-06, 9.99928951e-01, 6.16544348e-05],\n",
       "       [1.49821898e-03, 9.81449604e-01, 1.70521028e-02],\n",
       "       [6.63491346e-06, 9.97066438e-01, 2.92689726e-03],\n",
       "       [2.45963633e-02, 9.74356115e-01, 1.04745605e-03],\n",
       "       [5.73758327e-04, 8.55012178e-01, 1.44414097e-01],\n",
       "       [4.03068581e-04, 9.21585560e-01, 7.80113935e-02],\n",
       "       [6.33066869e-04, 9.98382449e-01, 9.84477694e-04],\n",
       "       [2.02583960e-05, 9.99186695e-01, 7.93009531e-04],\n",
       "       [5.56385098e-03, 9.82501984e-01, 1.19342003e-02],\n",
       "       [2.51220888e-04, 7.68830180e-01, 2.30918527e-01],\n",
       "       [2.16285753e-06, 9.79175568e-01, 2.08222494e-02],\n",
       "       [1.30599828e-05, 9.97438431e-01, 2.54845945e-03],\n",
       "       [7.95736833e-06, 9.99147773e-01, 8.44258699e-04],\n",
       "       [7.75229884e-03, 7.11679399e-01, 2.80568302e-01],\n",
       "       [6.48066361e-07, 9.97968495e-01, 2.03085830e-03],\n",
       "       [9.99134481e-02, 8.64926279e-01, 3.51602957e-02],\n",
       "       [5.16349375e-02, 8.83798420e-01, 6.45667017e-02],\n",
       "       [6.49600551e-09, 9.95893359e-01, 4.10665805e-03],\n",
       "       [9.90399058e-05, 9.99143124e-01, 7.57735805e-04],\n",
       "       [5.11034068e-06, 8.93778503e-01, 1.06216401e-01],\n",
       "       [3.17408485e-05, 7.83119261e-01, 2.16849029e-01],\n",
       "       [4.85733617e-03, 7.77285039e-01, 2.17857689e-01],\n",
       "       [1.80437311e-03, 9.63765621e-01, 3.44300382e-02],\n",
       "       [8.45738570e-04, 9.78114486e-01, 2.10398659e-02],\n",
       "       [1.22184632e-02, 9.07281995e-01, 8.04995596e-02],\n",
       "       [6.31158194e-03, 9.64237869e-01, 2.94505265e-02],\n",
       "       [6.54928153e-03, 9.61140037e-01, 3.23106237e-02],\n",
       "       [1.09383414e-04, 2.48689100e-01, 7.51201510e-01],\n",
       "       [1.46161085e-02, 4.86388728e-02, 9.36745048e-01],\n",
       "       [1.07264255e-04, 9.36689675e-01, 6.32030144e-02],\n",
       "       [6.94326765e-04, 9.87444222e-01, 1.18615637e-02],\n",
       "       [3.67635257e-05, 1.41936354e-03, 9.98543859e-01],\n",
       "       [1.20167818e-03, 7.09873438e-03, 9.91699576e-01],\n",
       "       [1.65393308e-03, 5.62854037e-02, 9.42060649e-01],\n",
       "       [5.12317978e-02, 1.57955274e-01, 7.90812910e-01],\n",
       "       [2.94762081e-03, 1.19505427e-03, 9.95857298e-01],\n",
       "       [7.89861042e-06, 5.26012992e-03, 9.94732022e-01],\n",
       "       [3.57612967e-04, 6.39030933e-01, 3.60611409e-01],\n",
       "       [4.67704987e-04, 1.68656018e-02, 9.82666731e-01],\n",
       "       [4.97065522e-02, 1.65925976e-02, 9.33700919e-01],\n",
       "       [4.37126175e-07, 1.42212712e-05, 9.99985337e-01],\n",
       "       [5.46928030e-04, 3.36076878e-02, 9.65845406e-01],\n",
       "       [1.37035334e-02, 2.09198776e-03, 9.84204471e-01],\n",
       "       [1.05986162e-03, 5.66797191e-03, 9.93272245e-01],\n",
       "       [8.27320328e-04, 2.72115059e-02, 9.71961141e-01],\n",
       "       [8.21436424e-06, 2.80714594e-04, 9.99711096e-01],\n",
       "       [2.06832447e-05, 5.77448693e-04, 9.99401927e-01],\n",
       "       [2.47026997e-04, 1.04912911e-02, 9.89261746e-01],\n",
       "       [3.92611837e-04, 7.29752555e-02, 9.26632166e-01],\n",
       "       [9.75293282e-04, 4.55749629e-04, 9.98568892e-01],\n",
       "       [2.81202490e-03, 2.69509368e-02, 9.70237017e-01],\n",
       "       [3.19745345e-03, 5.09096868e-02, 9.45892811e-01],\n",
       "       [1.60816708e-04, 5.39433502e-04, 9.99299765e-01],\n",
       "       [5.19995291e-09, 7.55830797e-07, 9.99999285e-01],\n",
       "       [4.20819051e-05, 2.09655315e-01, 7.90302575e-01],\n",
       "       [4.69664665e-04, 7.51858056e-02, 9.24344540e-01],\n",
       "       [2.30272485e-06, 1.35153568e-05, 9.99984145e-01],\n",
       "       [7.64503347e-05, 6.78732842e-02, 9.32050288e-01],\n",
       "       [2.20343992e-01, 5.99809503e-03, 7.73657918e-01],\n",
       "       [2.58320938e-07, 2.79519300e-04, 9.99720156e-01],\n",
       "       [5.58550644e-04, 3.62085757e-06, 9.99437869e-01],\n",
       "       [8.27148091e-04, 9.35814828e-02, 9.05591369e-01],\n",
       "       [8.30491263e-06, 7.50794243e-07, 9.99990940e-01],\n",
       "       [3.43415362e-04, 3.85537058e-01, 6.14119470e-01],\n",
       "       [2.53236853e-02, 5.36666512e-01, 4.38009828e-01],\n",
       "       [4.00783465e-05, 1.48022012e-03, 9.98479664e-01],\n",
       "       [4.54993977e-04, 2.25769997e-01, 7.73775041e-01],\n",
       "       [9.54220593e-02, 5.47254562e-01, 3.57323349e-01],\n",
       "       [1.19460770e-03, 1.32630140e-01, 8.66175294e-01],\n",
       "       [5.54750368e-05, 2.46628630e-03, 9.97478187e-01],\n",
       "       [1.46384482e-05, 7.78353587e-02, 9.22150016e-01],\n",
       "       [7.78104761e-04, 5.67298234e-01, 4.31923658e-01],\n",
       "       [1.53074026e-01, 2.95638070e-02, 8.17362130e-01],\n",
       "       [1.84050687e-02, 5.57306483e-02, 9.25864279e-01],\n",
       "       [8.03410134e-04, 4.84429687e-01, 5.14766872e-01],\n",
       "       [2.88883150e-02, 1.27648830e-01, 8.43462884e-01],\n",
       "       [6.45065520e-05, 4.71352832e-04, 9.99464095e-01],\n",
       "       [1.97581165e-02, 4.81733203e-01, 4.98508692e-01],\n",
       "       [8.92270691e-05, 5.74789126e-04, 9.99335945e-01],\n",
       "       [8.86948158e-07, 8.97878528e-01, 1.02120601e-01],\n",
       "       [5.98504084e-05, 1.10467397e-01, 8.89472783e-01],\n",
       "       [4.49889228e-07, 1.20329112e-03, 9.98796225e-01],\n",
       "       [2.58004526e-04, 1.30302962e-02, 9.86711621e-01],\n",
       "       [5.10730835e-09, 2.66375721e-01, 7.33624279e-01],\n",
       "       [4.50349338e-02, 2.63719335e-02, 9.28593159e-01],\n",
       "       [1.51900476e-05, 1.76663452e-05, 9.99967098e-01],\n",
       "       [2.92531740e-06, 3.01625580e-01, 6.98371530e-01],\n",
       "       [4.46707008e-06, 3.80778533e-06, 9.99991775e-01],\n",
       "       [1.36675535e-05, 2.75959348e-04, 9.99710381e-01],\n",
       "       [8.64408685e-06, 9.81592108e-04, 9.99009728e-01],\n",
       "       [8.22709990e-06, 1.69593113e-04, 9.99822199e-01],\n",
       "       [2.04102304e-02, 3.05349827e-02, 9.49054778e-01],\n",
       "       [1.57278366e-04, 1.16978663e-05, 9.99830961e-01],\n",
       "       [3.11624113e-04, 9.16767299e-01, 8.29210803e-02],\n",
       "       [2.30214269e-07, 7.71793566e-06, 9.99992013e-01],\n",
       "       [4.51344531e-04, 2.49119811e-02, 9.74636674e-01],\n",
       "       [3.30544310e-03, 2.93791518e-02, 9.67315435e-01],\n",
       "       [3.02965987e-06, 2.73825657e-02, 9.72614467e-01],\n",
       "       [5.20772255e-06, 9.61451791e-03, 9.90380287e-01],\n",
       "       [1.76361186e-06, 4.76337016e-01, 5.23661256e-01],\n",
       "       [2.85374208e-05, 1.11880573e-02, 9.88783419e-01],\n",
       "       [2.12643456e-04, 8.60727072e-01, 1.39060348e-01],\n",
       "       [9.69730027e-05, 3.55421565e-03, 9.96348739e-01],\n",
       "       [1.69251219e-03, 2.06084549e-03, 9.96246636e-01],\n",
       "       [3.43976339e-04, 1.22008249e-04, 9.99534011e-01],\n",
       "       [7.33582965e-06, 5.37504442e-04, 9.99455154e-01],\n",
       "       [1.35778170e-02, 1.04958616e-01, 8.81463528e-01],\n",
       "       [1.51485161e-04, 1.60764921e-02, 9.83771980e-01],\n",
       "       [2.94554717e-04, 1.50226817e-01, 8.49478602e-01],\n",
       "       [8.69238429e-05, 3.81217309e-04, 9.99531865e-01],\n",
       "       [4.88791920e-05, 3.92931653e-03, 9.96021807e-01],\n",
       "       [1.11570080e-06, 1.03565813e-04, 9.99895334e-01],\n",
       "       [3.32067575e-04, 9.09955561e-01, 8.97124186e-02],\n",
       "       [1.28376216e-03, 2.51826248e-04, 9.98464465e-01],\n",
       "       [1.09390367e-03, 1.97214391e-02, 9.79184628e-01],\n",
       "       [5.05343303e-02, 3.01163703e-01, 6.48302019e-01],\n",
       "       [5.72764874e-02, 4.21737358e-02, 9.00549829e-01],\n",
       "       [6.70741405e-03, 1.19700190e-02, 9.81322527e-01],\n",
       "       [1.56717878e-02, 5.89736044e-01, 3.94592226e-01],\n",
       "       [3.39273475e-02, 6.96157336e-01, 2.69915313e-01],\n",
       "       [1.75752997e-04, 7.38292001e-03, 9.92441297e-01],\n",
       "       [1.21199584e-03, 4.60248262e-01, 5.38539708e-01],\n",
       "       [2.35151360e-03, 2.56110006e-03, 9.95087445e-01],\n",
       "       [2.96410769e-02, 3.45716858e-03, 9.66901779e-01],\n",
       "       [8.55227187e-02, 2.01288704e-02, 8.94348383e-01],\n",
       "       [1.20438740e-01, 3.11543457e-02, 8.48406911e-01],\n",
       "       [7.20270813e-01, 1.30761313e-04, 2.79598415e-01],\n",
       "       [2.34305812e-03, 3.92241520e-04, 9.97264743e-01],\n",
       "       [1.91152245e-02, 4.84360792e-02, 9.32448745e-01],\n",
       "       [5.00152290e-01, 1.55506685e-04, 4.99692202e-01],\n",
       "       [2.53594667e-02, 1.59049593e-02, 9.58735526e-01],\n",
       "       [7.01931059e-01, 1.57617815e-05, 2.98053235e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(validation_generator)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_classes = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,   1,  10],\n",
       "       [  1, 137,  12],\n",
       "       [  3,  10,  88]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(validation_generator.classes, preds_classes) #, labels=[\"covid19\", \"normal\", \"pneumonia\"])\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     covid19       0.84      0.66      0.74        32\n",
      "      normal       0.93      0.91      0.92       150\n",
      "   pneumonia       0.80      0.87      0.83       101\n",
      "\n",
      "    accuracy                           0.87       283\n",
      "   macro avg       0.86      0.81      0.83       283\n",
      "weighted avg       0.87      0.87      0.87       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(validation_generator.classes, preds_classes, target_names=[\"covid19\", \"normal\", \"pneumonia\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "#     plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plot_confusion_matrix(cm = cf, \n",
    "                      normalize    = False,\n",
    "                      target_names = [\"covid19\", \"normal\", \"pneumonia\"],\n",
    "                      title        = \"\")\n",
    "plt.savefig('../docs/' + model.name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
