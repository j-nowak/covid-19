{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '../data/processed'\n",
    "DATASET_TRAIN = DATASET_ROOT + '/train'\n",
    "DATASET_TEST = DATASET_ROOT + '/test'\n",
    "\n",
    "SAVED_MODELS_PATH = '../saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1615 images belonging to 3 classes.\n",
      "Found 283 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_TRAIN,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        DATASET_TEST,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def vgg16_based_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(150, 150, 3)))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x, name='vgg16_based')\n",
    "    return model\n",
    "\n",
    "\n",
    "def residual_block(x, filters_num):\n",
    "    x_residual = x\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters_num, (3, 3), padding='same')(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters_num, (3, 3), padding='same')(x)\n",
    "    \n",
    "    x = tf.keras.layers.add([x, x_residual])\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample(x, filters_num):\n",
    "    x = Conv2D(filters_num, kernel_size=(4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_simple_model():\n",
    "    model_input = Input(shape=(150, 150, 3))\n",
    "    x = BatchNormalization()(model_input)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = downsample(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = downsample(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = downsample(x, 64)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=x, name='simple_residual')\n",
    "    return model\n",
    "              \n",
    "    \n",
    "model = resnet_simple_model()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_residual\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 150, 150, 3)  12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 150, 150, 64) 1792        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 150, 150, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 150, 150, 64) 256         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 150, 150, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 150, 150, 64) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 150, 150, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 150, 150, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 150, 150, 64) 0           conv2d_2[0][0]                   \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 150, 150, 64) 256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 150, 150, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 64) 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 150, 150, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 150, 150, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 150, 150, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 150, 150, 64) 0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 128)  131200      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 75, 75, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 75, 75, 128)  512         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 75, 75, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 75, 75, 128)  147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 75, 75, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 75, 75, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 75, 75, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 75, 75, 128)  0           conv2d_7[0][0]                   \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 75, 75, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 75, 75, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 75, 75, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 75, 75, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 75, 75, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 75, 75, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 75, 75, 128)  0           conv2d_9[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 38, 38, 128)  262272      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 38, 38, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 128)  512         batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 38, 38, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 38, 38, 128)  147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 38, 38, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 38, 38, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 38, 38, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 38, 38, 128)  0           conv2d_12[0][0]                  \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 38, 38, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 38, 38, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 38, 38, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 38, 38, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 38, 38, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 38, 38, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 38, 38, 128)  0           conv2d_14[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 19, 19, 64)   131136      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 19, 19, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 23104)        0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           1478720     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            195         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,340,111\n",
      "Trainable params: 3,336,905\n",
      "Non-trainable params: 3,206\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time_now = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "path_to_save = SAVED_MODELS_PATH + '/' + model.name + '_' + time_now\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(path_to_save, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-0071fc268ffb>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 17 steps\n",
      "Epoch 1/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5186 - accuracy: 0.5092WARNING:tensorflow:From /home/jakub/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 110s 1s/step - loss: 1.5162 - accuracy: 0.5103 - val_loss: 2.3478 - val_accuracy: 0.2978\n",
      "Epoch 2/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.5483INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.9703 - accuracy: 0.5485 - val_loss: 0.9486 - val_accuracy: 0.5625\n",
      "Epoch 3/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.9217 - accuracy: 0.5472 - val_loss: 0.9532 - val_accuracy: 0.6360\n",
      "Epoch 4/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8856 - accuracy: 0.6033INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.8854 - accuracy: 0.6035 - val_loss: 0.8266 - val_accuracy: 0.5846\n",
      "Epoch 5/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8381 - accuracy: 0.6115INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.8390 - accuracy: 0.6104 - val_loss: 0.7925 - val_accuracy: 0.6912\n",
      "Epoch 6/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.8077 - accuracy: 0.6348 - val_loss: 0.8035 - val_accuracy: 0.6765\n",
      "Epoch 7/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8516 - accuracy: 0.6235INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.8534 - accuracy: 0.6229 - val_loss: 0.7889 - val_accuracy: 0.7206\n",
      "Epoch 8/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8329 - accuracy: 0.6077INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.8315 - accuracy: 0.6073 - val_loss: 0.7274 - val_accuracy: 0.7096\n",
      "Epoch 9/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.7881 - accuracy: 0.6429 - val_loss: 0.7753 - val_accuracy: 0.6875\n",
      "Epoch 10/1000000\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.8433 - accuracy: 0.6191 - val_loss: 3.9797 - val_accuracy: 0.4926\n",
      "Epoch 11/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.8416 - accuracy: 0.6054 - val_loss: 0.8230 - val_accuracy: 0.6949\n",
      "Epoch 12/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.7856 - accuracy: 0.6354 - val_loss: 0.7451 - val_accuracy: 0.6654\n",
      "Epoch 13/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8210 - accuracy: 0.6488INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.8184 - accuracy: 0.6498 - val_loss: 0.7112 - val_accuracy: 0.7059\n",
      "Epoch 14/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.8076 - accuracy: 0.6735 - val_loss: 0.8362 - val_accuracy: 0.6801\n",
      "Epoch 15/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.7922 - accuracy: 0.6698 - val_loss: 0.7597 - val_accuracy: 0.7316\n",
      "Epoch 16/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.7885 - accuracy: 0.6473 - val_loss: 0.8191 - val_accuracy: 0.6618\n",
      "Epoch 17/1000000\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.7841 - accuracy: 0.6635 - val_loss: 0.8231 - val_accuracy: 0.6544\n",
      "Epoch 18/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.8083 - accuracy: 0.6654 - val_loss: 0.7352 - val_accuracy: 0.7096\n",
      "Epoch 19/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.8362 - accuracy: 0.6542 - val_loss: 0.7170 - val_accuracy: 0.6875\n",
      "Epoch 20/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7784 - accuracy: 0.6589INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.7808 - accuracy: 0.6585 - val_loss: 0.7023 - val_accuracy: 0.7426\n",
      "Epoch 21/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.7823 - accuracy: 0.6654 - val_loss: 0.7838 - val_accuracy: 0.7132\n",
      "Epoch 22/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7910 - accuracy: 0.6667 - val_loss: 0.7173 - val_accuracy: 0.7353\n",
      "Epoch 23/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7853 - accuracy: 0.6633INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.7862 - accuracy: 0.6617 - val_loss: 0.6917 - val_accuracy: 0.7353\n",
      "Epoch 24/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7906 - accuracy: 0.6735 - val_loss: 0.7357 - val_accuracy: 0.7132\n",
      "Epoch 25/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.7709 - accuracy: 0.6473 - val_loss: 0.7313 - val_accuracy: 0.7243\n",
      "Epoch 26/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.7781 - accuracy: 0.6504 - val_loss: 0.6986 - val_accuracy: 0.7243\n",
      "Epoch 27/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.7808 - accuracy: 0.6710 - val_loss: 0.8811 - val_accuracy: 0.6287\n",
      "Epoch 28/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7877 - accuracy: 0.6642 - val_loss: 0.6932 - val_accuracy: 0.7243\n",
      "Epoch 29/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7908 - accuracy: 0.6671INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.7897 - accuracy: 0.6673 - val_loss: 0.6851 - val_accuracy: 0.7132\n",
      "Epoch 30/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7665 - accuracy: 0.6728INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.7671 - accuracy: 0.6735 - val_loss: 0.6816 - val_accuracy: 0.7316\n",
      "Epoch 31/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.7692 - accuracy: 0.6673 - val_loss: 0.6997 - val_accuracy: 0.7279\n",
      "Epoch 32/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.7710 - accuracy: 0.6729 - val_loss: 0.7187 - val_accuracy: 0.6949\n",
      "Epoch 33/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7569 - accuracy: 0.6598 - val_loss: 0.7126 - val_accuracy: 0.7279\n",
      "Epoch 34/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.7539 - accuracy: 0.6673 - val_loss: 0.7819 - val_accuracy: 0.6765\n",
      "Epoch 35/1000000\n",
      "100/100 [==============================] - 96s 962ms/step - loss: 0.7511 - accuracy: 0.6617 - val_loss: 0.7115 - val_accuracy: 0.7243\n",
      "Epoch 36/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.7710 - accuracy: 0.6729 - val_loss: 0.7031 - val_accuracy: 0.7390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.7880 - accuracy: 0.6679 - val_loss: 0.6972 - val_accuracy: 0.7500\n",
      "Epoch 38/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7460 - accuracy: 0.6723 - val_loss: 0.6917 - val_accuracy: 0.7243\n",
      "Epoch 39/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7550 - accuracy: 0.6604 - val_loss: 0.7911 - val_accuracy: 0.7169\n",
      "Epoch 40/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.7633 - accuracy: 0.6673 - val_loss: 0.7105 - val_accuracy: 0.7243\n",
      "Epoch 41/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.7800 - accuracy: 0.6529 - val_loss: 0.8002 - val_accuracy: 0.6691\n",
      "Epoch 42/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.7822 - accuracy: 0.6235 - val_loss: 0.7667 - val_accuracy: 0.6691\n",
      "Epoch 43/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.7600 - accuracy: 0.6604 - val_loss: 0.7147 - val_accuracy: 0.7426\n",
      "Epoch 44/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.7499 - accuracy: 0.6754 - val_loss: 0.7154 - val_accuracy: 0.7206\n",
      "Epoch 45/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.7530 - accuracy: 0.6785 - val_loss: 0.7383 - val_accuracy: 0.7353\n",
      "Epoch 46/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7410 - accuracy: 0.6660 - val_loss: 0.7009 - val_accuracy: 0.7426\n",
      "Epoch 47/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.7633 - accuracy: 0.6685 - val_loss: 0.6943 - val_accuracy: 0.7206\n",
      "Epoch 48/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7660 - accuracy: 0.6797INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.7680 - accuracy: 0.6798 - val_loss: 0.6813 - val_accuracy: 0.7243\n",
      "Epoch 49/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7466 - accuracy: 0.6911INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.7484 - accuracy: 0.6911 - val_loss: 0.6669 - val_accuracy: 0.7316\n",
      "Epoch 50/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.7328 - accuracy: 0.7029 - val_loss: 0.7630 - val_accuracy: 0.6765\n",
      "Epoch 51/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7281 - accuracy: 0.6667 - val_loss: 0.8036 - val_accuracy: 0.6765\n",
      "Epoch 52/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.7559 - accuracy: 0.6642 - val_loss: 0.7171 - val_accuracy: 0.6875\n",
      "Epoch 53/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.7545 - accuracy: 0.6592 - val_loss: 0.8047 - val_accuracy: 0.6250\n",
      "Epoch 54/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.7431 - accuracy: 0.6767 - val_loss: 0.6768 - val_accuracy: 0.7574\n",
      "Epoch 55/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.7370 - accuracy: 0.6742 - val_loss: 0.7348 - val_accuracy: 0.7243\n",
      "Epoch 56/1000000\n",
      "100/100 [==============================] - 96s 963ms/step - loss: 0.7263 - accuracy: 0.6817 - val_loss: 0.6950 - val_accuracy: 0.7426\n",
      "Epoch 57/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.7414 - accuracy: 0.6792 - val_loss: 0.6904 - val_accuracy: 0.7353\n",
      "Epoch 58/1000000\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.7434 - accuracy: 0.6892 - val_loss: 0.6999 - val_accuracy: 0.7316\n",
      "Epoch 59/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.7316 - accuracy: 0.6823 - val_loss: 0.7684 - val_accuracy: 0.6985\n",
      "Epoch 60/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7372 - accuracy: 0.6779 - val_loss: 0.7078 - val_accuracy: 0.7279\n",
      "Epoch 61/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.7506 - accuracy: 0.6717 - val_loss: 0.7563 - val_accuracy: 0.6838\n",
      "Epoch 62/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.7411 - accuracy: 0.6854 - val_loss: 0.7556 - val_accuracy: 0.6801\n",
      "Epoch 63/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.7420 - accuracy: 0.6836 - val_loss: 0.7545 - val_accuracy: 0.7132\n",
      "Epoch 64/1000000\n",
      "100/100 [==============================] - 95s 945ms/step - loss: 0.7110 - accuracy: 0.6873 - val_loss: 0.8003 - val_accuracy: 0.7353\n",
      "Epoch 65/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.7570 - accuracy: 0.6710 - val_loss: 0.7059 - val_accuracy: 0.6985\n",
      "Epoch 66/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.7348 - accuracy: 0.6779 - val_loss: 0.6789 - val_accuracy: 0.7206\n",
      "Epoch 67/1000000\n",
      "100/100 [==============================] - 94s 945ms/step - loss: 0.7395 - accuracy: 0.6911 - val_loss: 0.6999 - val_accuracy: 0.7426\n",
      "Epoch 68/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.7374 - accuracy: 0.6698 - val_loss: 0.6948 - val_accuracy: 0.7206\n",
      "Epoch 69/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.7421 - accuracy: 0.6942 - val_loss: 0.6846 - val_accuracy: 0.7463\n",
      "Epoch 70/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.7244 - accuracy: 0.6873 - val_loss: 0.7368 - val_accuracy: 0.6949\n",
      "Epoch 71/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.7344 - accuracy: 0.6754 - val_loss: 0.7470 - val_accuracy: 0.7426\n",
      "Epoch 72/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.7165 - accuracy: 0.6961 - val_loss: 0.7369 - val_accuracy: 0.7426\n",
      "Epoch 73/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.7089 - accuracy: 0.6992 - val_loss: 0.7782 - val_accuracy: 0.6544\n",
      "Epoch 74/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.7279 - accuracy: 0.6717 - val_loss: 0.7079 - val_accuracy: 0.7132\n",
      "Epoch 75/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.7552 - accuracy: 0.6698 - val_loss: 0.6895 - val_accuracy: 0.7132\n",
      "Epoch 76/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.7319 - accuracy: 0.6829 - val_loss: 0.7174 - val_accuracy: 0.6985\n",
      "Epoch 77/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.7385 - accuracy: 0.6848 - val_loss: 0.7387 - val_accuracy: 0.7169\n",
      "Epoch 78/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.7629 - accuracy: 0.6904 - val_loss: 0.7415 - val_accuracy: 0.7243\n",
      "Epoch 79/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.7047 - accuracy: 0.6873 - val_loss: 0.7134 - val_accuracy: 0.7096\n",
      "Epoch 80/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.7097 - accuracy: 0.6986 - val_loss: 0.7088 - val_accuracy: 0.7279\n",
      "Epoch 81/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.7247 - accuracy: 0.6735 - val_loss: 0.7571 - val_accuracy: 0.7316\n",
      "Epoch 82/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.7073 - accuracy: 0.6879 - val_loss: 0.7045 - val_accuracy: 0.7279\n",
      "Epoch 83/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.6848 - accuracy: 0.7011 - val_loss: 0.7972 - val_accuracy: 0.6949\n",
      "Epoch 84/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.7098 - accuracy: 0.7079 - val_loss: 0.7952 - val_accuracy: 0.7353\n",
      "Epoch 85/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.7015 - accuracy: 0.6811 - val_loss: 0.7724 - val_accuracy: 0.7390\n",
      "Epoch 86/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.7168 - accuracy: 0.6942 - val_loss: 0.7325 - val_accuracy: 0.7132\n",
      "Epoch 87/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.7019 - accuracy: 0.6900 - val_loss: 1.0115 - val_accuracy: 0.6507\n",
      "Epoch 88/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7360 - accuracy: 0.6898 - val_loss: 0.7410 - val_accuracy: 0.7426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.7132 - accuracy: 0.6967 - val_loss: 0.7027 - val_accuracy: 0.7132\n",
      "Epoch 90/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.7025 - accuracy: 0.6898 - val_loss: 0.6897 - val_accuracy: 0.7059\n",
      "Epoch 91/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.7049 - accuracy: 0.7054 - val_loss: 0.6955 - val_accuracy: 0.7096\n",
      "Epoch 92/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.6899 - accuracy: 0.7061 - val_loss: 0.6999 - val_accuracy: 0.7132\n",
      "Epoch 93/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.7146 - accuracy: 0.6929 - val_loss: 0.6983 - val_accuracy: 0.7059\n",
      "Epoch 94/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.6908 - accuracy: 0.7061 - val_loss: 0.7704 - val_accuracy: 0.7316\n",
      "Epoch 95/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7036 - accuracy: 0.7018INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.7029 - accuracy: 0.7023 - val_loss: 0.6574 - val_accuracy: 0.7279\n",
      "Epoch 96/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6864 - accuracy: 0.7233INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.6878 - accuracy: 0.7236 - val_loss: 0.6548 - val_accuracy: 0.7096\n",
      "Epoch 97/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7023 - accuracy: 0.7113INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.7034 - accuracy: 0.7104 - val_loss: 0.6527 - val_accuracy: 0.7353\n",
      "Epoch 98/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.6749 - accuracy: 0.7205 - val_loss: 0.6807 - val_accuracy: 0.7279\n",
      "Epoch 99/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.6985 - accuracy: 0.7017 - val_loss: 0.6936 - val_accuracy: 0.7169\n",
      "Epoch 100/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.6608 - accuracy: 0.7261 - val_loss: 0.6729 - val_accuracy: 0.6838\n",
      "Epoch 101/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.6798 - accuracy: 0.7217 - val_loss: 0.7061 - val_accuracy: 0.7096\n",
      "Epoch 102/1000000\n",
      "100/100 [==============================] - 94s 945ms/step - loss: 0.6861 - accuracy: 0.7023 - val_loss: 0.7570 - val_accuracy: 0.7132\n",
      "Epoch 103/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.6938 - accuracy: 0.7117 - val_loss: 0.6864 - val_accuracy: 0.7096\n",
      "Epoch 104/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.6657 - accuracy: 0.7042 - val_loss: 0.6702 - val_accuracy: 0.7059\n",
      "Epoch 105/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.6726 - accuracy: 0.7048 - val_loss: 0.6720 - val_accuracy: 0.7390\n",
      "Epoch 106/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.6750 - accuracy: 0.7242 - val_loss: 0.6950 - val_accuracy: 0.7022\n",
      "Epoch 107/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.6643 - accuracy: 0.7261 - val_loss: 0.6716 - val_accuracy: 0.7169\n",
      "Epoch 108/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.6668 - accuracy: 0.7154 - val_loss: 0.6806 - val_accuracy: 0.7206\n",
      "Epoch 109/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.6704 - accuracy: 0.7255 - val_loss: 0.6811 - val_accuracy: 0.7096\n",
      "Epoch 110/1000000\n",
      "100/100 [==============================] - 95s 945ms/step - loss: 0.6818 - accuracy: 0.7261 - val_loss: 0.6626 - val_accuracy: 0.7132\n",
      "Epoch 111/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.6388 - accuracy: 0.7330 - val_loss: 0.6910 - val_accuracy: 0.7537\n",
      "Epoch 112/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.6703 - accuracy: 0.7098 - val_loss: 0.7331 - val_accuracy: 0.6912\n",
      "Epoch 113/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6347 - accuracy: 0.7303INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.6378 - accuracy: 0.7292 - val_loss: 0.5918 - val_accuracy: 0.7574\n",
      "Epoch 114/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.6475 - accuracy: 0.7448 - val_loss: 0.7017 - val_accuracy: 0.7243\n",
      "Epoch 115/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.6585 - accuracy: 0.7179 - val_loss: 0.7248 - val_accuracy: 0.7426\n",
      "Epoch 116/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.6358 - accuracy: 0.7280 - val_loss: 0.6197 - val_accuracy: 0.7574\n",
      "Epoch 117/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.6596 - accuracy: 0.7255 - val_loss: 0.7156 - val_accuracy: 0.7096\n",
      "Epoch 118/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.6378 - accuracy: 0.7411 - val_loss: 0.6067 - val_accuracy: 0.7390\n",
      "Epoch 119/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.6131 - accuracy: 0.7598 - val_loss: 0.6554 - val_accuracy: 0.7500\n",
      "Epoch 120/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.6212 - accuracy: 0.7367 - val_loss: 0.6923 - val_accuracy: 0.7426\n",
      "Epoch 121/1000000\n",
      "100/100 [==============================] - 94s 938ms/step - loss: 0.6547 - accuracy: 0.7317 - val_loss: 0.6448 - val_accuracy: 0.7132\n",
      "Epoch 122/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.6432 - accuracy: 0.7455 - val_loss: 0.6003 - val_accuracy: 0.7500\n",
      "Epoch 123/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.6066 - accuracy: 0.7667 - val_loss: 0.6587 - val_accuracy: 0.7390\n",
      "Epoch 124/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.6176 - accuracy: 0.7436 - val_loss: 0.6450 - val_accuracy: 0.7574\n",
      "Epoch 125/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.5834 - accuracy: 0.7567 - val_loss: 0.7136 - val_accuracy: 0.7574\n",
      "Epoch 126/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.6340 - accuracy: 0.7398 - val_loss: 0.7194 - val_accuracy: 0.7390\n",
      "Epoch 127/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.7555INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.6205 - accuracy: 0.7567 - val_loss: 0.5852 - val_accuracy: 0.7721\n",
      "Epoch 128/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.6045 - accuracy: 0.7530 - val_loss: 0.7168 - val_accuracy: 0.6985\n",
      "Epoch 129/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.6123 - accuracy: 0.7542 - val_loss: 0.6928 - val_accuracy: 0.7316\n",
      "Epoch 130/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.6283 - accuracy: 0.7480 - val_loss: 0.6716 - val_accuracy: 0.7169\n",
      "Epoch 131/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.6080 - accuracy: 0.7467 - val_loss: 0.6606 - val_accuracy: 0.7537\n",
      "Epoch 132/1000000\n",
      "100/100 [==============================] - 96s 962ms/step - loss: 0.5974 - accuracy: 0.7586 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 133/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.6170 - accuracy: 0.7473 - val_loss: 0.8299 - val_accuracy: 0.7610\n",
      "Epoch 134/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.6228 - accuracy: 0.7448 - val_loss: 0.6119 - val_accuracy: 0.7537\n",
      "Epoch 135/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.6064 - accuracy: 0.7498 - val_loss: 0.7261 - val_accuracy: 0.7647\n",
      "Epoch 136/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.5970 - accuracy: 0.7455 - val_loss: 0.7085 - val_accuracy: 0.7684\n",
      "Epoch 137/1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 96s 959ms/step - loss: 0.5924 - accuracy: 0.7486 - val_loss: 0.6768 - val_accuracy: 0.7463\n",
      "Epoch 138/1000000\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 0.5747 - accuracy: 0.7655 - val_loss: 0.6854 - val_accuracy: 0.7647\n",
      "Epoch 139/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5652 - accuracy: 0.7649 - val_loss: 0.6299 - val_accuracy: 0.7757\n",
      "Epoch 140/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.5812 - accuracy: 0.7649 - val_loss: 0.7564 - val_accuracy: 0.7390\n",
      "Epoch 141/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.5752 - accuracy: 0.7711 - val_loss: 0.7703 - val_accuracy: 0.7647\n",
      "Epoch 142/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5793 - accuracy: 0.7749 - val_loss: 0.6565 - val_accuracy: 0.7537\n",
      "Epoch 143/1000000\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 0.5874 - accuracy: 0.7505 - val_loss: 0.6316 - val_accuracy: 0.7647\n",
      "Epoch 144/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.5807 - accuracy: 0.7655 - val_loss: 0.6893 - val_accuracy: 0.7463\n",
      "Epoch 145/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5857 - accuracy: 0.7561 - val_loss: 0.5880 - val_accuracy: 0.7574\n",
      "Epoch 146/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.5974 - accuracy: 0.7392 - val_loss: 0.7067 - val_accuracy: 0.7279\n",
      "Epoch 147/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.5898 - accuracy: 0.7617 - val_loss: 0.7330 - val_accuracy: 0.7647\n",
      "Epoch 148/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5775 - accuracy: 0.7674 - val_loss: 0.7730 - val_accuracy: 0.7537\n",
      "Epoch 149/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5603 - accuracy: 0.7736 - val_loss: 0.7070 - val_accuracy: 0.7463\n",
      "Epoch 150/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.5980 - accuracy: 0.7561 - val_loss: 0.5945 - val_accuracy: 0.7610\n",
      "Epoch 151/1000000\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.5746 - accuracy: 0.7592 - val_loss: 0.5967 - val_accuracy: 0.7904\n",
      "Epoch 152/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.5225 - accuracy: 0.7886 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
      "Epoch 153/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.6088 - accuracy: 0.7523 - val_loss: 0.8793 - val_accuracy: 0.7463\n",
      "Epoch 154/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.5620 - accuracy: 0.7642 - val_loss: 0.6802 - val_accuracy: 0.8051\n",
      "Epoch 155/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5698 - accuracy: 0.7625INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.5721 - accuracy: 0.7636 - val_loss: 0.5563 - val_accuracy: 0.7794\n",
      "Epoch 156/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.5358 - accuracy: 0.7742 - val_loss: 0.6955 - val_accuracy: 0.7721\n",
      "Epoch 157/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5630 - accuracy: 0.7711 - val_loss: 0.6349 - val_accuracy: 0.7831\n",
      "Epoch 158/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5323 - accuracy: 0.7774 - val_loss: 0.6309 - val_accuracy: 0.7574\n",
      "Epoch 159/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5444 - accuracy: 0.7917 - val_loss: 0.6380 - val_accuracy: 0.7868\n",
      "Epoch 160/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.5583 - accuracy: 0.7742 - val_loss: 0.6809 - val_accuracy: 0.7647\n",
      "Epoch 161/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.5649 - accuracy: 0.7711 - val_loss: 0.6762 - val_accuracy: 0.7941\n",
      "Epoch 162/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.5444 - accuracy: 0.7899 - val_loss: 0.6553 - val_accuracy: 0.7574\n",
      "Epoch 163/1000000\n",
      "100/100 [==============================] - 94s 936ms/step - loss: 0.5631 - accuracy: 0.7642 - val_loss: 0.7396 - val_accuracy: 0.7721\n",
      "Epoch 164/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.5514 - accuracy: 0.7799 - val_loss: 0.6173 - val_accuracy: 0.7978\n",
      "Epoch 165/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.5332 - accuracy: 0.7874 - val_loss: 0.6221 - val_accuracy: 0.7684\n",
      "Epoch 166/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.5373 - accuracy: 0.7899 - val_loss: 0.6290 - val_accuracy: 0.7500\n",
      "Epoch 167/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.5747 - accuracy: 0.7611 - val_loss: 0.6314 - val_accuracy: 0.7390\n",
      "Epoch 168/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.5494 - accuracy: 0.7736 - val_loss: 0.6874 - val_accuracy: 0.7721\n",
      "Epoch 169/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.5258 - accuracy: 0.7774 - val_loss: 0.6266 - val_accuracy: 0.7684\n",
      "Epoch 170/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5285 - accuracy: 0.7899 - val_loss: 0.6054 - val_accuracy: 0.7463\n",
      "Epoch 171/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5477 - accuracy: 0.7761 - val_loss: 0.6293 - val_accuracy: 0.7757\n",
      "Epoch 172/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.5364 - accuracy: 0.7736 - val_loss: 0.7601 - val_accuracy: 0.7390\n",
      "Epoch 173/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5266 - accuracy: 0.7811 - val_loss: 0.6281 - val_accuracy: 0.7831\n",
      "Epoch 174/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.5061 - accuracy: 0.7992 - val_loss: 0.7096 - val_accuracy: 0.7684\n",
      "Epoch 175/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.5101 - accuracy: 0.7874 - val_loss: 0.6301 - val_accuracy: 0.7721\n",
      "Epoch 176/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5477 - accuracy: 0.7917 - val_loss: 0.6029 - val_accuracy: 0.7610\n",
      "Epoch 177/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.5456 - accuracy: 0.7774 - val_loss: 0.6395 - val_accuracy: 0.7794\n",
      "Epoch 178/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.5252 - accuracy: 0.7761 - val_loss: 0.6516 - val_accuracy: 0.7647\n",
      "Epoch 179/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.5193 - accuracy: 0.7994 - val_loss: 0.6787 - val_accuracy: 0.7868\n",
      "Epoch 180/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.5369 - accuracy: 0.7767 - val_loss: 0.7922 - val_accuracy: 0.7941\n",
      "Epoch 181/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.5145 - accuracy: 0.7861 - val_loss: 0.6009 - val_accuracy: 0.8125\n",
      "Epoch 182/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5135 - accuracy: 0.7930 - val_loss: 0.6595 - val_accuracy: 0.7537\n",
      "Epoch 183/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.4976 - accuracy: 0.7969 - val_loss: 0.6946 - val_accuracy: 0.7426\n",
      "Epoch 184/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5155 - accuracy: 0.7849 - val_loss: 0.5665 - val_accuracy: 0.8015\n",
      "Epoch 185/1000000\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 0.5131 - accuracy: 0.7892 - val_loss: 0.7473 - val_accuracy: 0.7610\n",
      "Epoch 186/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5091 - accuracy: 0.8011 - val_loss: 0.6013 - val_accuracy: 0.7426\n",
      "Epoch 187/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.7928INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.5099 - accuracy: 0.7942 - val_loss: 0.5518 - val_accuracy: 0.8088\n",
      "Epoch 188/1000000\n",
      "100/100 [==============================] - 94s 945ms/step - loss: 0.5281 - accuracy: 0.7761 - val_loss: 0.6938 - val_accuracy: 0.7868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5065 - accuracy: 0.7899 - val_loss: 0.5754 - val_accuracy: 0.7647\n",
      "Epoch 190/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5343 - accuracy: 0.7842 - val_loss: 0.6904 - val_accuracy: 0.8015\n",
      "Epoch 191/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.4875 - accuracy: 0.8011 - val_loss: 0.6087 - val_accuracy: 0.8015\n",
      "Epoch 192/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.4857 - accuracy: 0.8024 - val_loss: 0.8640 - val_accuracy: 0.7721\n",
      "Epoch 193/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.4930 - accuracy: 0.8136 - val_loss: 0.5721 - val_accuracy: 0.7868\n",
      "Epoch 194/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.5241 - accuracy: 0.7880 - val_loss: 0.6091 - val_accuracy: 0.7647\n",
      "Epoch 195/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.4754 - accuracy: 0.8118 - val_loss: 0.6778 - val_accuracy: 0.6912\n",
      "Epoch 196/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.5012 - accuracy: 0.7924 - val_loss: 0.6172 - val_accuracy: 0.7831\n",
      "Epoch 197/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.4828 - accuracy: 0.7924 - val_loss: 0.6145 - val_accuracy: 0.7426\n",
      "Epoch 198/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4916 - accuracy: 0.7880 - val_loss: 0.6742 - val_accuracy: 0.7610\n",
      "Epoch 199/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.4970 - accuracy: 0.7942 - val_loss: 0.6435 - val_accuracy: 0.7757\n",
      "Epoch 200/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.5022 - accuracy: 0.7899 - val_loss: 0.7156 - val_accuracy: 0.7794\n",
      "Epoch 201/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4986 - accuracy: 0.7880 - val_loss: 0.5700 - val_accuracy: 0.7757\n",
      "Epoch 202/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.4757 - accuracy: 0.7905 - val_loss: 0.7321 - val_accuracy: 0.7941\n",
      "Epoch 203/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.5030 - accuracy: 0.7974 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
      "Epoch 204/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.4644 - accuracy: 0.8168 - val_loss: 0.5678 - val_accuracy: 0.7647\n",
      "Epoch 205/1000000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.8117INFO:tensorflow:Assets written to: ../saved_models/simple_residual_2020_05_01__21_58_00/assets\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.4459 - accuracy: 0.8105 - val_loss: 0.5180 - val_accuracy: 0.8309\n",
      "Epoch 206/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.4709 - accuracy: 0.8055 - val_loss: 0.7026 - val_accuracy: 0.7904\n",
      "Epoch 207/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.4791 - accuracy: 0.7917 - val_loss: 0.8547 - val_accuracy: 0.8125\n",
      "Epoch 208/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.4894 - accuracy: 0.8061 - val_loss: 0.5820 - val_accuracy: 0.7941\n",
      "Epoch 209/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.4549 - accuracy: 0.8118 - val_loss: 0.7971 - val_accuracy: 0.7757\n",
      "Epoch 210/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.4634 - accuracy: 0.8074 - val_loss: 0.7588 - val_accuracy: 0.7978\n",
      "Epoch 211/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4479 - accuracy: 0.8111 - val_loss: 0.7401 - val_accuracy: 0.8088\n",
      "Epoch 212/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.4314 - accuracy: 0.8143 - val_loss: 0.7138 - val_accuracy: 0.8051\n",
      "Epoch 213/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.4627 - accuracy: 0.8068 - val_loss: 0.7371 - val_accuracy: 0.7904\n",
      "Epoch 214/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.4601 - accuracy: 0.8205 - val_loss: 0.5962 - val_accuracy: 0.8051\n",
      "Epoch 215/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.4738 - accuracy: 0.8068 - val_loss: 0.6090 - val_accuracy: 0.7868\n",
      "Epoch 216/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.4442 - accuracy: 0.8180 - val_loss: 0.7541 - val_accuracy: 0.8125\n",
      "Epoch 217/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.4403 - accuracy: 0.8136 - val_loss: 0.6895 - val_accuracy: 0.8125\n",
      "Epoch 218/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.4520 - accuracy: 0.8199 - val_loss: 0.6634 - val_accuracy: 0.8199\n",
      "Epoch 219/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.4380 - accuracy: 0.8174 - val_loss: 0.7457 - val_accuracy: 0.7794\n",
      "Epoch 220/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4347 - accuracy: 0.8243 - val_loss: 0.6604 - val_accuracy: 0.7978\n",
      "Epoch 221/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.4629 - accuracy: 0.8055 - val_loss: 0.6414 - val_accuracy: 0.8088\n",
      "Epoch 222/1000000\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 0.4334 - accuracy: 0.8211 - val_loss: 0.6688 - val_accuracy: 0.7794\n",
      "Epoch 223/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.4465 - accuracy: 0.8249 - val_loss: 0.8596 - val_accuracy: 0.7978\n",
      "Epoch 224/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.4293 - accuracy: 0.8211 - val_loss: 0.7354 - val_accuracy: 0.8015\n",
      "Epoch 225/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.4529 - accuracy: 0.8205 - val_loss: 0.5557 - val_accuracy: 0.8162\n",
      "Epoch 226/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.4370 - accuracy: 0.8174 - val_loss: 0.5629 - val_accuracy: 0.8051\n",
      "Epoch 227/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4328 - accuracy: 0.8243 - val_loss: 0.6359 - val_accuracy: 0.7684\n",
      "Epoch 228/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.4306 - accuracy: 0.8268 - val_loss: 0.6003 - val_accuracy: 0.8051\n",
      "Epoch 229/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4165 - accuracy: 0.8255 - val_loss: 0.6526 - val_accuracy: 0.8162\n",
      "Epoch 230/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4215 - accuracy: 0.8268 - val_loss: 0.8060 - val_accuracy: 0.8051\n",
      "Epoch 231/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.4280 - accuracy: 0.8261 - val_loss: 0.6009 - val_accuracy: 0.7831\n",
      "Epoch 232/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.4391 - accuracy: 0.8211 - val_loss: 0.6058 - val_accuracy: 0.8162\n",
      "Epoch 233/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.4156 - accuracy: 0.8249 - val_loss: 0.6638 - val_accuracy: 0.7941\n",
      "Epoch 234/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.4094 - accuracy: 0.8318 - val_loss: 0.6274 - val_accuracy: 0.8051\n",
      "Epoch 235/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3829 - accuracy: 0.8418 - val_loss: 0.7311 - val_accuracy: 0.7868\n",
      "Epoch 236/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.3869 - accuracy: 0.8474 - val_loss: 0.7314 - val_accuracy: 0.8199\n",
      "Epoch 237/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4058 - accuracy: 0.8324 - val_loss: 0.7426 - val_accuracy: 0.8015\n",
      "Epoch 238/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.4096 - accuracy: 0.8386 - val_loss: 0.6435 - val_accuracy: 0.7904\n",
      "Epoch 239/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.3748 - accuracy: 0.8512 - val_loss: 0.7277 - val_accuracy: 0.8051\n",
      "Epoch 240/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.3744 - accuracy: 0.8405 - val_loss: 0.6030 - val_accuracy: 0.8015\n",
      "Epoch 241/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.4041 - accuracy: 0.8424 - val_loss: 0.7420 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.3862 - accuracy: 0.8493 - val_loss: 0.6332 - val_accuracy: 0.8235\n",
      "Epoch 243/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.4030 - accuracy: 0.8412 - val_loss: 0.8430 - val_accuracy: 0.8088\n",
      "Epoch 244/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.4359 - accuracy: 0.8361 - val_loss: 0.6293 - val_accuracy: 0.8235\n",
      "Epoch 245/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.3925 - accuracy: 0.8368 - val_loss: 0.9475 - val_accuracy: 0.8015\n",
      "Epoch 246/1000000\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 0.3913 - accuracy: 0.8424 - val_loss: 0.6766 - val_accuracy: 0.8125\n",
      "Epoch 247/1000000\n",
      "100/100 [==============================] - 94s 937ms/step - loss: 0.3815 - accuracy: 0.8450 - val_loss: 0.6253 - val_accuracy: 0.8162\n",
      "Epoch 248/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.3828 - accuracy: 0.8468 - val_loss: 0.7318 - val_accuracy: 0.7978\n",
      "Epoch 249/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.4054 - accuracy: 0.8424 - val_loss: 0.7480 - val_accuracy: 0.8088\n",
      "Epoch 250/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.3619 - accuracy: 0.8574 - val_loss: 0.7304 - val_accuracy: 0.8199\n",
      "Epoch 251/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.3909 - accuracy: 0.8355 - val_loss: 0.6881 - val_accuracy: 0.8125\n",
      "Epoch 252/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.3656 - accuracy: 0.8462 - val_loss: 0.9451 - val_accuracy: 0.8199\n",
      "Epoch 253/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3617 - accuracy: 0.8568 - val_loss: 0.7692 - val_accuracy: 0.7978\n",
      "Epoch 254/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.3724 - accuracy: 0.8468 - val_loss: 0.8896 - val_accuracy: 0.7941\n",
      "Epoch 255/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.3835 - accuracy: 0.8443 - val_loss: 0.6692 - val_accuracy: 0.8456\n",
      "Epoch 256/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.3506 - accuracy: 0.8618 - val_loss: 0.7312 - val_accuracy: 0.8272\n",
      "Epoch 257/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.3724 - accuracy: 0.8605 - val_loss: 0.6945 - val_accuracy: 0.8419\n",
      "Epoch 258/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.3466 - accuracy: 0.8605 - val_loss: 0.8598 - val_accuracy: 0.8088\n",
      "Epoch 259/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3471 - accuracy: 0.8618 - val_loss: 0.7321 - val_accuracy: 0.8088\n",
      "Epoch 260/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.3605 - accuracy: 0.8543 - val_loss: 0.9911 - val_accuracy: 0.8051\n",
      "Epoch 261/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.3351 - accuracy: 0.8649 - val_loss: 1.1245 - val_accuracy: 0.8272\n",
      "Epoch 262/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.3352 - accuracy: 0.8705 - val_loss: 0.6961 - val_accuracy: 0.7721\n",
      "Epoch 263/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.3561 - accuracy: 0.8574 - val_loss: 0.6253 - val_accuracy: 0.8125\n",
      "Epoch 264/1000000\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 0.3344 - accuracy: 0.8668 - val_loss: 0.6847 - val_accuracy: 0.7610\n",
      "Epoch 265/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.3850 - accuracy: 0.8537 - val_loss: 1.2113 - val_accuracy: 0.8015\n",
      "Epoch 266/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.3718 - accuracy: 0.8480 - val_loss: 0.7495 - val_accuracy: 0.8051\n",
      "Epoch 267/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.3485 - accuracy: 0.8674 - val_loss: 0.6315 - val_accuracy: 0.8235\n",
      "Epoch 268/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.3394 - accuracy: 0.8599 - val_loss: 0.7825 - val_accuracy: 0.7941\n",
      "Epoch 269/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.3449 - accuracy: 0.8593 - val_loss: 0.8082 - val_accuracy: 0.8272\n",
      "Epoch 270/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.3291 - accuracy: 0.8699 - val_loss: 0.6583 - val_accuracy: 0.7426\n",
      "Epoch 271/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3407 - accuracy: 0.8612 - val_loss: 0.6196 - val_accuracy: 0.7941\n",
      "Epoch 272/1000000\n",
      "100/100 [==============================] - 96s 961ms/step - loss: 0.3303 - accuracy: 0.8662 - val_loss: 0.6549 - val_accuracy: 0.8272\n",
      "Epoch 273/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.3391 - accuracy: 0.8674 - val_loss: 0.5503 - val_accuracy: 0.8235\n",
      "Epoch 274/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.3195 - accuracy: 0.8755 - val_loss: 0.6111 - val_accuracy: 0.8272\n",
      "Epoch 275/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.3545 - accuracy: 0.8649 - val_loss: 0.5598 - val_accuracy: 0.8015\n",
      "Epoch 276/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.3207 - accuracy: 0.8680 - val_loss: 0.6887 - val_accuracy: 0.7868\n",
      "Epoch 277/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.3324 - accuracy: 0.8662 - val_loss: 0.9158 - val_accuracy: 0.8088\n",
      "Epoch 278/1000000\n",
      "100/100 [==============================] - 95s 945ms/step - loss: 0.3129 - accuracy: 0.8737 - val_loss: 0.8632 - val_accuracy: 0.8272\n",
      "Epoch 279/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3142 - accuracy: 0.8868 - val_loss: 0.8324 - val_accuracy: 0.8235\n",
      "Epoch 280/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.2980 - accuracy: 0.8799 - val_loss: 0.8919 - val_accuracy: 0.8199\n",
      "Epoch 281/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.3164 - accuracy: 0.8687 - val_loss: 0.7318 - val_accuracy: 0.8125\n",
      "Epoch 282/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.3118 - accuracy: 0.8774 - val_loss: 0.7192 - val_accuracy: 0.8346\n",
      "Epoch 283/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.3255 - accuracy: 0.8662 - val_loss: 0.6766 - val_accuracy: 0.8235\n",
      "Epoch 284/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.3063 - accuracy: 0.8818 - val_loss: 0.7761 - val_accuracy: 0.8382\n",
      "Epoch 285/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.3163 - accuracy: 0.8787 - val_loss: 0.8206 - val_accuracy: 0.8125\n",
      "Epoch 286/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.3193 - accuracy: 0.8793 - val_loss: 0.6327 - val_accuracy: 0.8346\n",
      "Epoch 287/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3131 - accuracy: 0.8787 - val_loss: 0.6442 - val_accuracy: 0.8162\n",
      "Epoch 288/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.2832 - accuracy: 0.8906 - val_loss: 0.7745 - val_accuracy: 0.8015\n",
      "Epoch 289/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.2964 - accuracy: 0.8743 - val_loss: 0.8197 - val_accuracy: 0.7978\n",
      "Epoch 290/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.2860 - accuracy: 0.8881 - val_loss: 0.7199 - val_accuracy: 0.8272\n",
      "Epoch 291/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.2676 - accuracy: 0.9006 - val_loss: 1.0090 - val_accuracy: 0.8162\n",
      "Epoch 292/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.3022 - accuracy: 0.8881 - val_loss: 0.8194 - val_accuracy: 0.8088\n",
      "Epoch 293/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.3050 - accuracy: 0.8837 - val_loss: 0.7385 - val_accuracy: 0.7978\n",
      "Epoch 294/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2889 - accuracy: 0.8862 - val_loss: 1.0992 - val_accuracy: 0.7941\n",
      "Epoch 295/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.2814 - accuracy: 0.8874 - val_loss: 0.6747 - val_accuracy: 0.8346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.2759 - accuracy: 0.8887 - val_loss: 0.7807 - val_accuracy: 0.8015\n",
      "Epoch 297/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.3113 - accuracy: 0.8705 - val_loss: 0.8274 - val_accuracy: 0.8125\n",
      "Epoch 298/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.2658 - accuracy: 0.8999 - val_loss: 0.6099 - val_accuracy: 0.7978\n",
      "Epoch 299/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.2695 - accuracy: 0.8949 - val_loss: 0.8326 - val_accuracy: 0.8346\n",
      "Epoch 300/1000000\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 0.2964 - accuracy: 0.8799 - val_loss: 0.6871 - val_accuracy: 0.8199\n",
      "Epoch 301/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.2751 - accuracy: 0.8943 - val_loss: 0.9793 - val_accuracy: 0.8199\n",
      "Epoch 302/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.2639 - accuracy: 0.9043 - val_loss: 0.7513 - val_accuracy: 0.7868\n",
      "Epoch 303/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.2801 - accuracy: 0.8981 - val_loss: 0.7797 - val_accuracy: 0.7721\n",
      "Epoch 304/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.2748 - accuracy: 0.8937 - val_loss: 0.7922 - val_accuracy: 0.8199\n",
      "Epoch 305/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2628 - accuracy: 0.8968 - val_loss: 0.7621 - val_accuracy: 0.7831\n",
      "Epoch 306/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2850 - accuracy: 0.9024 - val_loss: 0.8277 - val_accuracy: 0.8125\n",
      "Epoch 307/1000000\n",
      "100/100 [==============================] - 94s 945ms/step - loss: 0.2873 - accuracy: 0.8893 - val_loss: 0.8139 - val_accuracy: 0.8125\n",
      "Epoch 308/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.2812 - accuracy: 0.8993 - val_loss: 0.8001 - val_accuracy: 0.8272\n",
      "Epoch 309/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 0.7330 - val_accuracy: 0.7831\n",
      "Epoch 310/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2395 - accuracy: 0.9099 - val_loss: 0.8505 - val_accuracy: 0.8199\n",
      "Epoch 311/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2643 - accuracy: 0.8899 - val_loss: 0.7683 - val_accuracy: 0.7684\n",
      "Epoch 312/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.2409 - accuracy: 0.9087 - val_loss: 0.6860 - val_accuracy: 0.8015\n",
      "Epoch 313/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.2742 - accuracy: 0.8899 - val_loss: 0.9313 - val_accuracy: 0.8088\n",
      "Epoch 314/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.2838 - accuracy: 0.8993 - val_loss: 0.9511 - val_accuracy: 0.8346\n",
      "Epoch 315/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.2353 - accuracy: 0.9149 - val_loss: 0.7989 - val_accuracy: 0.8309\n",
      "Epoch 316/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.2472 - accuracy: 0.9068 - val_loss: 1.0638 - val_accuracy: 0.8088\n",
      "Epoch 317/1000000\n",
      "100/100 [==============================] - 96s 958ms/step - loss: 0.2595 - accuracy: 0.9118 - val_loss: 0.8666 - val_accuracy: 0.8088\n",
      "Epoch 318/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.2552 - accuracy: 0.9006 - val_loss: 0.7198 - val_accuracy: 0.8382\n",
      "Epoch 319/1000000\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.2459 - accuracy: 0.9106 - val_loss: 0.9494 - val_accuracy: 0.7904\n",
      "Epoch 320/1000000\n",
      "100/100 [==============================] - 94s 944ms/step - loss: 0.2493 - accuracy: 0.9056 - val_loss: 0.9250 - val_accuracy: 0.8088\n",
      "Epoch 321/1000000\n",
      "100/100 [==============================] - 96s 960ms/step - loss: 0.2446 - accuracy: 0.9193 - val_loss: 0.7800 - val_accuracy: 0.8309\n",
      "Epoch 322/1000000\n",
      "100/100 [==============================] - 96s 959ms/step - loss: 0.2374 - accuracy: 0.9131 - val_loss: 0.8370 - val_accuracy: 0.8162\n",
      "Epoch 323/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.2264 - accuracy: 0.9187 - val_loss: 0.8793 - val_accuracy: 0.8199\n",
      "Epoch 324/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2430 - accuracy: 0.9131 - val_loss: 0.8917 - val_accuracy: 0.8346\n",
      "Epoch 325/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2359 - accuracy: 0.9124 - val_loss: 0.9025 - val_accuracy: 0.8051\n",
      "Epoch 326/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.2781 - accuracy: 0.9024 - val_loss: 0.9468 - val_accuracy: 0.7831\n",
      "Epoch 327/1000000\n",
      "100/100 [==============================] - 94s 941ms/step - loss: 0.2324 - accuracy: 0.9137 - val_loss: 0.8538 - val_accuracy: 0.8456\n",
      "Epoch 328/1000000\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 0.2077 - accuracy: 0.9306 - val_loss: 0.6319 - val_accuracy: 0.8125\n",
      "Epoch 329/1000000\n",
      "100/100 [==============================] - 95s 948ms/step - loss: 0.2175 - accuracy: 0.9199 - val_loss: 0.7913 - val_accuracy: 0.8309\n",
      "Epoch 330/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.2894 - accuracy: 0.9037 - val_loss: 0.6713 - val_accuracy: 0.8235\n",
      "Epoch 331/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2434 - accuracy: 0.9106 - val_loss: 0.6299 - val_accuracy: 0.8309\n",
      "Epoch 332/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.1984 - accuracy: 0.9318 - val_loss: 0.7885 - val_accuracy: 0.8199\n",
      "Epoch 333/1000000\n",
      "100/100 [==============================] - 93s 934ms/step - loss: 0.2281 - accuracy: 0.9174 - val_loss: 0.6644 - val_accuracy: 0.8529\n",
      "Epoch 334/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.2252 - accuracy: 0.9206 - val_loss: 0.6779 - val_accuracy: 0.8346\n",
      "Epoch 335/1000000\n",
      "100/100 [==============================] - 94s 943ms/step - loss: 0.2598 - accuracy: 0.9156 - val_loss: 0.7892 - val_accuracy: 0.8419\n",
      "Epoch 336/1000000\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 0.2480 - accuracy: 0.9081 - val_loss: 0.9884 - val_accuracy: 0.8456\n",
      "Epoch 337/1000000\n",
      "100/100 [==============================] - 96s 955ms/step - loss: 0.2235 - accuracy: 0.9174 - val_loss: 0.8199 - val_accuracy: 0.8346\n",
      "Epoch 338/1000000\n",
      "100/100 [==============================] - 95s 945ms/step - loss: 0.2022 - accuracy: 0.9287 - val_loss: 0.7191 - val_accuracy: 0.8382\n",
      "Epoch 339/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.2573 - accuracy: 0.9112 - val_loss: 0.7105 - val_accuracy: 0.8529\n",
      "Epoch 340/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2169 - accuracy: 0.9149 - val_loss: 0.8463 - val_accuracy: 0.8346\n",
      "Epoch 341/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2065 - accuracy: 0.9212 - val_loss: 0.8188 - val_accuracy: 0.8272\n",
      "Epoch 342/1000000\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.1740 - accuracy: 0.9375 - val_loss: 0.7652 - val_accuracy: 0.8493\n",
      "Epoch 343/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.2114 - accuracy: 0.9199 - val_loss: 0.6348 - val_accuracy: 0.8382\n",
      "Epoch 344/1000000\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.1937 - accuracy: 0.9250 - val_loss: 0.7746 - val_accuracy: 0.8346\n",
      "Epoch 345/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.2120 - accuracy: 0.9256 - val_loss: 0.9010 - val_accuracy: 0.8382\n",
      "Epoch 346/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.2008 - accuracy: 0.9293 - val_loss: 0.7634 - val_accuracy: 0.8456\n",
      "Epoch 347/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.1910 - accuracy: 0.9293 - val_loss: 1.0212 - val_accuracy: 0.8493\n",
      "Epoch 348/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2032 - accuracy: 0.9268 - val_loss: 1.0635 - val_accuracy: 0.7206\n",
      "Epoch 349/1000000\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.2161 - accuracy: 0.9225 - val_loss: 0.7079 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.1855 - accuracy: 0.9287 - val_loss: 0.9018 - val_accuracy: 0.8235\n",
      "Epoch 351/1000000\n",
      "100/100 [==============================] - 95s 953ms/step - loss: 0.1926 - accuracy: 0.9337 - val_loss: 1.0203 - val_accuracy: 0.8235\n",
      "Epoch 352/1000000\n",
      "100/100 [==============================] - 94s 939ms/step - loss: 0.1954 - accuracy: 0.9243 - val_loss: 0.9390 - val_accuracy: 0.8309\n",
      "Epoch 353/1000000\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.1979 - accuracy: 0.9362 - val_loss: 0.9575 - val_accuracy: 0.8162\n",
      "Epoch 354/1000000\n",
      "100/100 [==============================] - 95s 954ms/step - loss: 0.2087 - accuracy: 0.9275 - val_loss: 1.2382 - val_accuracy: 0.7978\n",
      "Epoch 355/1000000\n",
      "100/100 [==============================] - 95s 950ms/step - loss: 0.2035 - accuracy: 0.9212 - val_loss: 0.9127 - val_accuracy: 0.7831\n",
      "Epoch 356/1000000\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 0.2344 - accuracy: 0.9174 - val_loss: 0.7761 - val_accuracy: 0.8346\n",
      "Epoch 357/1000000\n",
      "100/100 [==============================] - 94s 940ms/step - loss: 0.1996 - accuracy: 0.9268 - val_loss: 0.6694 - val_accuracy: 0.8309\n",
      "Epoch 358/1000000\n",
      " 55/100 [===============>..............] - ETA: 50s - loss: 0.2144 - accuracy: 0.9224WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0071fc268ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/covid-19/env/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        epochs=1000000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEP_SIZE_VALID,\n",
    "        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid19': 0, 'normal': 1, 'pneumonia': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    SAVED_MODELS_PATH + '/' + 'vgg16_based_2020_05_01__12_22_15', custom_objects=None, compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(validation_generator)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_classes = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0,\n",
       "       2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,   4,   7],\n",
       "       [  1, 132,  17],\n",
       "       [  1,  19,  81]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(validation_generator.classes, preds_classes) #, labels=[\"covid19\", \"normal\", \"pneumonia\"])\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     covid19       0.91      0.66      0.76        32\n",
      "      normal       0.85      0.88      0.87       150\n",
      "   pneumonia       0.77      0.80      0.79       101\n",
      "\n",
      "    accuracy                           0.83       283\n",
      "   macro avg       0.85      0.78      0.81       283\n",
      "weighted avg       0.83      0.83      0.83       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(validation_generator.classes, preds_classes, target_names=[\"covid19\", \"normal\", \"pneumonia\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "#     plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = plot_confusion_matrix(cm = cf, \n",
    "                      normalize    = False,\n",
    "                      target_names = [\"covid19\", \"normal\", \"pneumonia\"],\n",
    "                      title        = \"\")\n",
    "plt.savefig('../docs/' + model.name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
